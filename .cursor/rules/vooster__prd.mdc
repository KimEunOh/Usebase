---
description:
globs:
alwaysApply: true
---
# 제품 요구사항 문서 (PRD)

## 1. 요약
‘Pay-per-use 종합 AI 플랫폼’은 LLM API를 기반으로 조직(시·도 공무원, 기업 단체 등)이 업무 특화 AI 모듈을 팀 단위로 사용하고 실제 사용량만큼만 과금받을 수 있는 웹/데스크톱 서비스다. 문서 기반 RAG, 실시간 검색, OCR, 기획서 작성 자동화 등을 통합 제공해 별도 월정액 없이 효율적·보안성 높은 AI 업무 환경을 제공한다.

## 2. 문제 정의
- 개별 직원이 서로 다른 AI 서비스에 각각 월정액을 결제 → 비용 중복, 관리 복잡.
- 공공·기업 조직은 기밀 데이터, 문서를 자체적으로 관리·검색·분석해야 하나, 범용 챗봇은 RAG·보안 기능 부족.
- LLM 사용비 예측 불가, 예산 확보 어려움 → 실제 사용량만큼 과금 필요.
- 통합 대시보드 없이 팀·조직별 사용량, 권한, 문서 관리가 단절.

## 3. 목표 및 목적
- 1차 목표: 팀·조직 단위 RAG+AI 작업 공간 제공, 사용량 기반 과금.
- 부차 목표:
  - 문서·데이터 수명주기 관리(추가, 삭제, 전처리, 폴더화)
  - 맞춤형 AI 모듈(기획서·보고서 자동 작성 등) 제공
  - 실시간 사용량 통계·비용 예측
- 성공 지표:
  - 조직별 월 활성 사용자(MAU) 70% 이상
  - LLM 호출당 평균 지연시간 1.5초 이하
  - 고객 이탈률 < 5%/분기
  - RAG 기반 응답 정확도 만족도 90% 이상

## 4. 대상 사용자
### 1차 사용자
- 지방자치단체, 공기업, 중대형 민간기업의 실무자·팀장  
- 필요: 보안 내재화, 문서 기반 AI 검색/작성, 예산 통제

### 2차 사용자
- IT 관리자: 사용자·권한·과금 관리  
- 경영진: 비용·생산성 리포트  
- AI 파트너사: API 마켓플레이스 연동

## 5. 사용자 스토리
- “시청 정책팀 직원으로서, 팀 공유폴더에 올린 조례 PDF를 바로 AI 검색해 초안 보고서를 작성하고 싶다.”
- “IT 관리자로서, 부서별 AI 사용량과 예상 비용을 월말 전에 파악해 예산을 조정하고 싶다.”
- “기업 전략담당자로서, 여러 형식의 경쟁사 보고서를 OCR 후 요약해 회의자료를 빠르게 만들고 싶다.”

## 6. 기능 요구사항
### 핵심 기능
1. RAG 문서 관리  
   - 업로드(폴더/드래그), 삭제, 버전관리  
   - 전처리: OCR·텍스트 추출, 문단 분할, 메타데이터 태깅  
   - 폴더·태그 기반 검색, 접근권한(조직·팀·개인)
   - 수락 기준: 1,000쪽 PDF 2분 내 인덱싱, 검색 정확도 ≥ 90%
2. 대화형 실시간 검색  
   - 자연어 질문→RAG 답변 + 출처 링크  
   - 실시간 스트리밍 응답(1초 이내 첫 토큰)
3. 문서·기획서 자동 작성 모듈  
   - 템플릿 선택 → 요구사항 입력 → 초안 생성  
   - 편집기 내 피드백 루프(“수치 업데이트” 등)
4. OCR 서비스  
   - 이미지·스캔 PDF 자동 감지, 한글 정확도 ≥ 95%
5. 사용량·과금 대시보드  
   - 조직/팀/사용자별 토큰·API 콜, 월 비용 예상  
   - CSV·PDF 내보내기
6. 인증·보안  
   - Supabase Auth (SAML/OAuth) 싱글사인온  
   - 역할 기반 접근제어(RBAC)  
   - 데이터 암호화 at-rest, in-transit

### 지원 기능 (Nice-to-have)
- 워크플로 자동화(예: 문서 업로드→자동 요약→메일 발송)
- 멀티언어 번역 및 다국어 RAG
- 음성→텍스트 STT, 회의록 요약
- 플러그인/마켓: 서드파티 AI 모듈 구독

## 7. 비기능 요구사항
- 성능: p95 응답 < 2.5초, 동시 세션 5,000
- 신뢰성: 월 가동률 99.9%
- 보안: ISMS·ISO27001 준수, 감사 로그 1년 보관
- 확장성: 멀티테넌트, 워크스페이스 수평 확장
- 호환성: 최신 Chrome/Edge, Windows 10+ 데스크톱 앱

## 8. 기술 고려사항
- 프런트엔드: Next.js 15 + TypeScript + Tailwind CSS
- 백엔드: Supabase(PostgreSQL, Storage, Auth), 파프리카형 LLM API 프록시
- 벡터 DB: pgvector (PostgreSQL 확장)  
- 인프라: Vercel(프런트), Supabase + Fly.io(백업 클러스터)
- 데스크톱: Electron + 동일 React 코드공유
- 서드파티: OpenAI, AWS Textract(OCR), 한국어 LLM 대안
- 데이터 거버넌스: 조직별 데이터 스키마 격리

## 9. 성공 지표
- 기능: 문서 업로드→검색→응답 완료 평균 3분 미만
- 비즈니스: 첫 6개월 유료 조직 100개, ARPU 30%↑
- 기술: p99 에러율 < 0.5%, 배포 후 롤백률 < 2%

## 10. 일정 및 마일스톤
| 단계 | 기간 | 주요 산출물 |
|---|---|---|
| Phase 1 MVP | M0–M3 | RAG·검색·대시보드·기본 과금 |
| Phase 2 확장 | M4–M6 | OCR, 문서 자동작성, SSO, 데스크톱 앱 |
| Phase 3 고도화 | M7–M9 | 워크플로 자동화, 마켓플레이스, 멀티언어 |

## 11. 위험 및 대응
- LLM 요금 폭증 → 캐싱·요약·토큰 절감 알고리즘 적용
- 공공기관 보안 규제 → 온프렘/프라이빗 배포 옵션 준비
- 사용자 교육 부족 → 인앱 튜토리얼, 정부기관 특화 세미나
- 벡터 검색 정확도 저하 → 하이브리드 BM25+벡터, 지속적 파인튜닝

## 12. 향후 고려사항
- 자체 한국어 LLM 파인튜닝으로 비용 절감
- 모바일 앱 제공, 오프라인 모드 지원
- AI 거버넌스(편향 모니터링, 감성 필터) 모듈
- API 마켓플레이스 확대, 서드파티 수익 쉐어 모델


